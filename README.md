# Ridges

去中心化的 AI 软件工程师系统，专注于自动化代码修复和创建任务。

## 📋 目录

- [Ridges](#ridges)
  - [📋 目录](#-目录)
  - [核心组件](#核心组件)
  - [架构概览](#架构概览)
  - [组件详解](#组件详解)
    - [Sandbox（沙箱）](#sandbox沙箱)
    - [Docker 容器化](#docker-容器化)
    - [Inference Gateway（推理网关）](#inference-gateway推理网关)
  - [工作流程](#工作流程)
    - [典型任务流程](#典型任务流程)
  - [为什么需要这些组件？](#为什么需要这些组件)
    - [安全性考虑](#安全性考虑)
    - [可靠性和一致性](#可靠性和一致性)
    - [可扩展性和维护性](#可扩展性和维护性)
    - [开发体验](#开发体验)
  - [总结](#总结)

---

## 核心组件

本系统主要由三个核心组件构成：

1. **Agent（智能代理）** - 执行代码修复和创建任务的 AI 代理
2. **Sandbox（沙箱）** - 提供隔离的执行环境
3. **Inference Gateway（推理网关）** - 统一的 LLM API 服务网关

---

## 架构概览

```
┌─────────────────────────────────────────────────────────────┐
│                      主机系统                                 │
│                                                               │
│  ┌──────────────────────────────────────────────────────┐   │
│  │        Inference Gateway (FastAPI 服务)              │   │
│  │  • 接收 LLM 推理请求                                    │   │
│  │  • 负载均衡到多个 LLM 提供商 (Chutes/Targon)            │   │
│  │  • 记录所有请求到数据库                                  │   │
│  └──────────────────────────────────────────────────────┘   │
│                        ↑                                      │
│                        │                                      │
│  ┌─────────────────────┴──────────────────────────────┐     │
│  │            Sandbox Proxy (Nginx)                     │     │
│  │  唯一可以访问互联网的 Docker 容器                       │     │
│  │  转发请求到 Inference Gateway                        │     │
│  └──────────────────────────────────────────────────────┘     │
│                        ↑                                      │
│                        │ (通过 Docker 内部网络)                 │
│         ┌──────────────┴──────────────┐                       │
│         │                              │                       │
│  ┌──────▼──────┐              ┌───────▼──────┐               │
│  │ Agent       │              │ Eval         │               │
│  │ Sandbox     │              │ Sandbox      │               │
│  │             │              │              │               │
│  │ • 运行 agent│              │ • 运行测试   │               │
│  │ • 修改代码   │              │ • 验证结果   │               │
│  │ • 无网络访问 │              │ • 无网络访问 │               │
│  └─────────────┘              └──────────────┘               │
│                                                               │
└─────────────────────────────────────────────────────────────┘
```

---

## 组件详解

### Sandbox（沙箱）

**作用**：提供完全隔离的执行环境，安全地运行 AI Agent 代码。

**主要功能**：

1. **环境隔离**
   - 每个任务在独立的 Docker 容器中运行
   - 无法访问主机系统的文件系统
   - 无法修改主机环境变量或系统设置

2. **网络隔离**
   - 默认情况下无法访问互联网
   - 只能通过专用的代理容器访问 Inference Gateway
   - 防止 Agent 代码进行未经授权的网络请求

3. **资源控制**
   - 可限制 CPU 和内存使用
   - 防止恶意代码消耗过多资源
   - 支持超时控制，避免任务无限运行

4. **环境一致性**
   - 所有任务在相同的 Python 环境中运行
   - 预装了所有必要的依赖包
   - 确保测试结果的可重复性

5. **两种沙箱类型**
   - **Agent Sandbox**：运行 Agent 代码，执行代码修复或创建任务
   - **Eval Sandbox**：运行测试套件，验证 Agent 的输出是否正确

**为什么需要沙箱**：
- 🔒 **安全性**：防止恶意或错误代码破坏主机系统
- 🎯 **隔离性**：每个任务互不干扰，并行运行多个任务
- 🧹 **可清理性**：任务完成后删除容器，不留任何痕迹
- 📊 **可追踪性**：所有操作都在容器内，易于审计和调试

---

### Docker 容器化

**作用**：使用 Docker 技术实现沙箱的隔离环境。

**为什么使用 Docker**：

1. **安全隔离**
   - Docker 容器提供了进程和文件系统的隔离
   - Agent 代码无法访问主机资源
   - 即使代码有恶意行为，也不会影响主机系统

2. **网络隔离**
   - Docker 内部网络（sandbox-network）将普通沙箱与互联网隔离
   - 只有代理容器可以访问互联网
   - Agent 必须通过代理才能访问 LLM 服务

3. **环境一致性**
   - Docker 镜像确保所有沙箱使用相同的环境
   - 包含预装的 Python 版本和所有依赖包
   - 消除了"在我机器上能运行"的问题

4. **资源控制**
   - Docker 可以限制容器的 CPU、内存使用
   - 防止单个任务占用过多资源
   - 支持超时自动终止容器

5. **易于管理**
   - 容器生命周期完全可控
   - 任务完成后可以快速清理
   - 支持并行运行多个隔离的任务

**Docker 网络架构**：

```
sandbox-network (内部网络)
├── sandbox_proxy (唯一可访问互联网)
│   └── 转发请求到 Inference Gateway
├── agent-sandbox-xxx (隔离环境)
│   └── 只能访问 sandbox_proxy
└── eval-sandbox-xxx (隔离环境)
    └── 只能访问 sandbox_proxy
```

---

### Inference Gateway（推理网关）

**作用**：为沙箱中的 Agent 提供统一的 LLM（大语言模型）推理服务。

**主要功能**：

1. **统一 API 接口**
   - 提供标准化的 `/api/inference` 端点
   - Agent 代码只需调用统一的接口，无需关心底层提供商
   - 简化 Agent 的开发和使用

2. **多提供商支持**
   - 支持多个 LLM 提供商（如 Chutes、Targon 等）
   - 根据模型名称自动选择合适的提供商
   - 支持扩展新的提供商

3. **负载均衡**
   - 使用加权随机算法分配请求
   - 避免单个提供商过载
   - 提高系统整体的可用性和性能

4. **请求管理**
   - 验证请求的有效性（如检查 evaluation run 状态）
   - 限制每个 evaluation run 的请求数量
   - 防止滥用和资源浪费

5. **数据记录**
   - 记录所有推理请求到数据库
   - 追踪使用的模型、token 数量、成本等信息
   - 支持后续分析和优化

6. **错误处理**
   - 统一的错误处理机制
   - 提供商故障时的自动降级
   - 详细的错误日志记录

**为什么需要 Inference Gateway**：

- 🌐 **解耦**：Agent 代码与具体的 LLM 提供商解耦
- ⚖️ **负载均衡**：智能分配请求，避免单个提供商过载
- 📝 **可追踪性**：记录所有请求，便于分析和审计
- 🔧 **易维护**：更换提供商时只需修改网关配置
- 🛡️ **安全性**：集中管理 API 密钥和访问控制

---

## 工作流程

### 典型任务流程

1. **初始化**
   - 启动 Inference Gateway 服务
   - 创建 Docker 网络（sandbox-network）
   - 启动代理容器（sandbox_proxy）

2. **Agent 执行阶段**
   - 创建 Agent Sandbox 容器
   - 将 Agent 代码和问题文件复制到容器
   - Agent 在隔离环境中执行任务
   - Agent 通过代理访问 Inference Gateway 获取 LLM 支持
   - 生成代码修复补丁（patch）

3. **验证阶段**
   - 创建 Eval Sandbox 容器
   - 应用 Agent 生成的补丁
   - 运行测试套件验证修复是否正确
   - 收集测试结果

4. **清理**
   - 停止并删除所有沙箱容器
   - 清理临时文件
   - 保存结果和日志

---

## 为什么需要这些组件？

### 安全性考虑

- **Sandbox**：防止恶意或错误代码破坏主机系统
- **Docker**：提供硬件级别的隔离，确保安全
- **网络隔离**：防止 Agent 进行未经授权的网络访问

### 可靠性和一致性

- **环境一致性**：所有任务在相同环境中运行，结果可复现
- **资源控制**：防止任务占用过多资源，影响其他任务
- **错误隔离**：一个任务的错误不会影响其他任务

### 可扩展性和维护性

- **Inference Gateway**：统一管理 LLM 服务，易于更换和扩展
- **负载均衡**：支持大规模并发任务
- **监控和日志**：便于追踪和分析系统行为

### 开发体验

- **解耦设计**：各组件职责清晰，易于开发和测试
- **本地开发**：可以在不使用 Docker 的情况下本地开发 Agent
- **调试友好**：沙箱环境可以重现问题，便于调试

---

## 总结

这三个组件（Sandbox、Docker、Inference Gateway）共同构成了一个**安全、可靠、可扩展**的 AI Agent 执行系统：

- **Sandbox** 提供隔离的执行环境
- **Docker** 提供底层容器化技术
- **Inference Gateway** 提供统一的 LLM 服务

它们协同工作，确保 AI Agent 可以在安全、可控的环境中执行任务，同时保持高性能和可维护性。

